# Dense retrieval

An embedding-based candidate retrieval pipeline for biomedical entity linking. UMLS concepts are encoded with discriminative LLMs, indexed in Qdrant, and queried at inference time to retrieve the most similar CUI labels filtered by semantic group.

## Pipeline overview

```
┌─────────────────────┐     ┌──────────────────┐     ┌──────────────────┐
│  1. generate        │     │  2. index        │     │  3. query        │
│     embeddings      │────▶│     qdrant       │────▶│     qdrant       │
│                     │     │                  │     │                  │
│  UMLS CSV ──▶ .bin  │     │  .bin ──▶ Qdrant │     │  CSV ──▶ results │
└─────────────────────┘     └──────────────────┘     └──────────────────┘
```

**Step 1** — Encode UMLS terms per ontology into dense embeddings and save as `.bin` files.  
**Step 2** — Create a Qdrant collection and upload all embeddings with metadata (term, ontology, CUIs).  
**Step 3** — For each input mention, encode the query with the same model, search Qdrant filtered by source ontology, apply semantic group filtering, and save ranked CUI candidates.

## Requirements

- Python ≥ 3.8
- CUDA-compatible GPU
- Flash Attention 2 support
- Qdrant server running (default: `http://localhost:6340`)

Install dependencies:

```bash
pip install -r requirements.txt
```

## Project structure

```
.
├── config.py                  # Shared configuration for all steps
├── generate_embeddings.py     # Step 1: Generate embeddings
├── index_qdrant.py            # Step 2: Index into Qdrant
├── query_qdrant.py            # Step 3: Query and retrieve candidates
├── requirements.txt           # Python dependencies
├── README.md
├── data/
│   ├── umls2025_terms_ontologies.csv
│   ├── umls_mappings/
│   │   └── cui_semantic_mapping.json
│   └── medlexalign/
│       ├── train.csv
│       ├── dev.csv
        └── test.csv
│
├── embeddings/                # Generated by step 1
│   └── nvidia-llama-embed-nemotron-8b/
│       ├── embedding_<ontology>_nvidia-llama-embed-nemotron-8b.bin
│       └── ...
└── outputs/                   # Generated by step 3
    └── dr_output/
        ├── train/
        ├── dev/
        └── test/
```

## Configuration

All parameters are centralized in `config.py`:

```python
# --- Model --- 
model_name = "nvidia/llama-embed-nemotron-8b" ## or any other model supported by SentenceTransformer

# --- Step 1: Embedding Generation ---
embedding_input_file = "data/umls2025_terms_ontologies.csv"
embedding_output_dir = "embeddings"
embedding_batch_size = 500

# --- Step 2: Qdrant Indexing ---
qdrant_url = "http://localhost:6340"
qdrant_collection_name = "nvidiallama"
qdrant_upload_batch_size = 200

# --- Step 3: Query / Retrieval ---
query_data_dir = "data/medlexalign"
query_output_dir = "outputs/dr_output"
query_splits = ["test"]
query_top_k_fetch = 500
query_top_k_save = 100
query_batch_size = 50
cui_semantic_mapping_path = "data/umls_mappings/cui_semantic_mapping.json"
```

See `config.py` for the full list of parameters, including Qdrant collection settings and the dataset-to-ontology mapping.

## Usage

### Step 1: Generate embeddings

```bash
python generate_embeddings.py
```

Reads the UMLS CSV, filters by each ontology column, and writes one `.bin` file per ontology to `embeddings/<model-name>/`.

### Step 2: Index into Qdrant

Make sure Qdrant is running, then:

```bash
python index_qdrant.py
```

Creates the collection and uploads all embedding files. Each point stores the term vector, ontology label, and associated CUI list. If the collection already exists, it is automatically deleted and recreated.

### Step 3: query and retrieve candidates

```bash
python query_qdrant.py
```

For each split (e.g., test), processes all dataset CSVs, encodes mentions with the same model, searches Qdrant filtered by relevant ontologies, applies semantic group filtering, and saves results.

## Input/output formats

### UMLS CSV (step 1 input)

The CSV contains UMLS terms with their CUI codes. The remaining columns are ontology indicators (binary 0/1) such as ATC, LOINC, SNOMEDCT_US, MSH, etc.

| term | CUI | ATC | SNOMEDCT_US | MSH | ... |
|---|---|---|---|---|---|
| myocardial infarction | ['C0027051'] | 0 | 1 | 1 | ... |
| headache | ['C0018681'] | 0 | 1 | 1 | ... |

### Embedding .bin files (step 1 output/ step 2 input)

```python
[{"term": "myocardial infarction", "embedding": np.ndarray(1024,), "cuis": ["C0027051"]}, ...]
```

### Query CSV (step 3 input)

| term | code | source | semantic_group |
|---|---|---|---|
| heart attack | ['C0027051'] | bc5cdr | ['Disorders'] |

### Result CSV (step 3 output)

| term | code | source | semantic_group | retrieved_codes | retrieved_scores |
|---|---|---|---|---|---|
| heart attack | ['C0027051'] | bc5cdr | ['DISO'] | ['C0027051', ...] | [0.95, ...] |
